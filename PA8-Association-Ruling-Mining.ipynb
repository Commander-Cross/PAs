{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [CPSC 322](https://github.com/GonzagaCPSC322) Data Science Algorithms\n",
    "[Gonzaga University](https://www.gonzaga.edu/)\n",
    "\n",
    "[Gina Sprint](http://cs.gonzaga.edu/faculty/sprint/)\n",
    "\n",
    "# PA8 Association Rule Mining (100 pts)\n",
    "\n",
    "## Learner Objectives\n",
    "At the conclusion of this programming assignment, participants should be able to:\n",
    "* Perform association rule mining using the apriori algorithm\n",
    "* Evaluate rules using rule interestingness measures\n",
    "\n",
    "## Prerequisites\n",
    "Before starting this programming assignment, participants should be able to:\n",
    "* Implement test-driven development\n",
    "* Evaluate classifiers using train/test sets\n",
    "* Tell a data science story using Jupyter Notebook\n",
    "* Understand Bramer Chapters 16 (Association Rule Mining I) and 17 (Association Rule Mining II)\n",
    "\n",
    "## Acknowledgments\n",
    "Content used in this assignment is based upon information in the following sources:\n",
    "* Dr. Shawn Bowers' Data Mining HW7"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Github Classroom Setup\n",
    "For this assignment, you will use GitHub Classroom to create a private code repository to track code changes and submit your assignment. Open this PA8 link to accept the assignment and create a private repository for your assignment in Github classroom: https://classroom.github.com/a/iaFnGiVR\n",
    "\n",
    "Your repo, for example, will be named GonzagaCPSC322/pa8-yourusername (where yourusername is your Github username). I highly recommend committing/pushing regularly so your work is always backed up. We will grade your most recent commit, even if that commit is after the due date (your work will be marked late if this is the case)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview and Requirements\n",
    "This assignment involves implementing an association rule miner. It has two main parts:\n",
    "1. `mysklearn`: Test and implement a general and re-usable unsupervised learning algorithm for association rule mining\n",
    "1. Datasets\n",
    "    1. Titanic Dataset Mining (pa7-titanic.ipynb): Write a Jupyter Notebook that uses `mysklearn` to perform rule mining tasks on a titanic survival dataset\n",
    "    1. Mushroom Dataset Mining (pa7-mushroom.ipynb): Write a Jupyter Notebook that uses `mysklearn` to perform rule mining tasks on a mushroom dataset\n",
    "\n",
    "I highly encourage you to design functions that are generic and re-usable for future programming assignments and data mining tasks.\n",
    "\n",
    "Note: we are learning data science from scratch! The only non-standard Python libraries you should need to use for this assignment are `tabulate`, `numpy` (math functions, random number generation, etc.), and `scipy` (sparingly). This means that beyond these libraries, you should not `pip install` any additional libraries beyond what is included in the [continuumio/anaconda3:2022.05](https://hub.docker.com/r/continuumio/anaconda3) Docker image and you should not use `pandas/sklearn/`etc... (exceptions are made for testing purposes only!!)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1: `mysklearn` (55 pts)\n",
    "Our association rule miner we are going to implement for PA7 will:\n",
    "* Be constructed using the apriori algorithm from class\n",
    "* Generate a set of rules with their corresponding support, confidence, and lift \"interestingness\" measures\n",
    "* Be parameterized to accept different min-support (`minsup`) and confidence (`minconf`) values\n",
    "* \"Pretty print\" the discovered rules with their corresponding support, confidence, and lift values (see the example pretty print below for the interview dataset)\n",
    "\n",
    "### Step 1: Implement an Association Rule Unit Test for `myruleminer.py`\n",
    "Finish the association rule unit test `test_association_rule_miner_fit()` in `test_myruleminer.py` for testing the `MyAssociationRuleMiner` method `fit(X_train)` by implementing the following test cases:\n",
    "1. Use the 8 instance toy \"market basket analysis\" dataset example traced in class, asserting against the rules and metrics constructed in [B Apriori Tasks #4 and #5](https://github.com/GonzagaCPSC322/U8-Unsupervised-Learning/blob/master/B%20Apriori.ipynb).\n",
    "1. Use the 14 instance \"interview\" dataset example traced in class, asserting against the rules provided and metrics computed in [A Association Rule Mining Lab Task #3](https://github.com/GonzagaCPSC322/U8-Unsupervised-Learning/blob/master/A%20Association%20Rule%20Mining.ipynb)\n",
    "```\n",
    "        \n",
    "For convenience, I've provided the toy \"market basket analysis\" and \"interview\" datasets as Python lists below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# toy market basket analysis dataset\n",
    "transactions = [\n",
    "    [\"b\", \"c\", \"m\"],\n",
    "    [\"b\", \"c\", \"e\", \"m\", \"s\"],\n",
    "    [\"b\"],\n",
    "    [\"c\", \"e\", \"s\"],\n",
    "    [\"c\"],\n",
    "    [\"b\", \"c\", \"s\"],\n",
    "    [\"c\", \"e\", \"s\"],\n",
    "    [\"c\", \"e\"]\n",
    "]\n",
    "\n",
    "# interview dataset\n",
    "header = [\"level\", \"lang\", \"tweets\", \"phd\", \"interviewed_well\"]\n",
    "table = [\n",
    "        [\"Senior\", \"Java\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"Java\", \"no\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"R\", \"yes\", \"yes\", \"False\"],\n",
    "        [\"Mid\", \"R\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"no\", \"no\", \"False\"],\n",
    "        [\"Senior\", \"R\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Senior\", \"Python\", \"yes\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Python\", \"no\", \"yes\", \"True\"],\n",
    "        [\"Mid\", \"Java\", \"yes\", \"no\", \"True\"],\n",
    "        [\"Junior\", \"Python\", \"no\", \"yes\", \"False\"]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: `fit()`\n",
    "Complete the `mysklearn.myruleminer.MyAssociationRuleMiner` method `fit()` and test your code for functional correctness against the `test_association_rule_miner_fit()` unit test."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 3: `print_association_rules()`\n",
    "Finish the `print_association_rules()` method of `MyAssociationRuleMiner` that \"pretty prints\" the rules inferred from apriori created from a call to `fit()`. Display the discovered rules with their corresponding support, confidence, and lift values. For example, for the interview dataset:\n",
    "\n",
    "```\n",
    "  # association rule                                  support    confidence    lift\n",
    "--- ----------------------------------------------  ---------  ------------  -------\n",
    "  1 IF interviewed_well=False THEN tweets=no             ???        ???       ???\n",
    "  2 IF level=Mid THEN interviewed_well=True              ???        ???       ???\n",
    "  3 IF tweets=yes THEN interviewed_well=True             ???        ???       ???\n",
    "  4 IF lang=R THEN tweets=yes                            ???        ???       ???\n",
    "  5 IF phd=no AND tweets=yes THEN interviewed_well=True  ???        ???       ???\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2: Datasets (30 pts)\n",
    "### Step 1: üö¢ Titanic Rule Mining üö¢ \n",
    "Run your apriori algorithm over the titanic dataset. Run and analyze your results using different min support and confidence values. Write a short description of the rules your implementation found, focusing on:\n",
    "1. Whether they make sense to you\n",
    "1. How they compare (if at all) to your classification results from PA7\n",
    "1. How the different values of min support and confidence changed the rules generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Step 2: üçÑ Mushroom Rule Mining üçÑ \n",
    "Run your apriori algorithm over the mushroom dataset. The \"preprocessed\" agaricus-lepiota.txt dataset represents information about different types of mushrooms and whether they are edible or poisonous. This dataset has 23 nominal features (by order in the following table):\n",
    "\n",
    "1. The class label edible=e, poisonous=p\n",
    "2. cap-shape bell=b, conical=c, convex=x, flat=f, knobbed=k, sunken=s\n",
    "3. cap-surface fibrous=f, grooves=g, scaly=y, smooth=s\n",
    "4. cap-color brown=n, buff=b, cinnamon=c, gray=g, green=r, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "5. bruises? bruises=t, no=f\n",
    "6. odor almond=a, anise=l, creosote=c, fishy=y, foul=f, musty=m, none=n, pungent=p, spicy=s\n",
    "7. gill-attachment attached=a, descending=d, free=f, notched=n\n",
    "8. gill-spacing close=c, crowded=w, distant=d\n",
    "9. gill-size broad=b, narrow=n\n",
    "10. gill-color black=k, brown=n, buff=b, chocolate=h, gray=g, green=r, orange=o, pink=p, purple=u, red=e, white=w, yellow=y\n",
    "11. stalk-shape enlarging=e, tapering=t\n",
    "12. stalk-root bulbous=b, club=c, cup=u, equal=e, rhizomorphs=z, rooted=r\n",
    "13. stalk-surface-above-ring fibrous=f,scaly=y,silky=k,smooth=s\n",
    "14. stalk-surface-below-ring fibrous=f,scaly=y,silky=k,smooth=s\n",
    "15. stalk-color-above-ring brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "16. stalk-color-below-ring brown=n, buff=b, cinnamon=c, gray=g, orange=o, pink=p, red=e, white=w, yellow=y\n",
    "17. veil-type partial=p, universal=u\n",
    "18. veil-color brown=n, orange=o, white=w, yellow=y\n",
    "19. ring-number none=n, one=o, two=t\n",
    "20. ring-type cobwebby=c, evanescent=e, flaring=f, large=l, none=n, pendant=p, sheathing=s, zone=z\n",
    "21. spore-print-color black=k, brown=n, buff=b, chocolate=h, green=r, orange=o, purple=u, white=w, yellow=y\n",
    "22. population abundant=a, clustered=c, numerous=n, scattered=s, several=v, solitary=y\n",
    "23. habitat grasses=g, leaves=l, meadows=m, paths=p, urban=u, waste=w, woods=d\n",
    "\n",
    "For this dataset, you will want to do feature selection (because of the number of attributes). Try using different subsets of features (though always include the class feature) and report on the effect of the rules generated and the performance in terms of the time it takes for your implementation to find the rules. You can measure execution time using the [time](https://docs.python.org/3/library/time.html) Python standard library, which has a [time() function](https://docs.python.org/3/library/time.html#time.time) you can use to find the elapsed execution time. Alternatively, you can use the [%time or %timeit IPython magic commands](https://jakevdp.github.io/PythonDataScienceHandbook/01.07-timing-and-profiling.html) to measure the time it takes to run a line (called line magic, `%`) or a cell (called cell magic `%%`) in a Jupyter Notebook.\n",
    "\n",
    "Like with the Titanic dataset, run and analyze your results using different min support and confidence values. Write a short description of the rules your implementation found, focusing on:\n",
    "1. Whether they make sense to you (look at rules with features you're familiar with, like mushroom odor üòã or ü§¢?)\n",
    "1. How the different values of min support and confidence changed the rules generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submitting Assignments\n",
    "1. Use Github classroom to submit your assignment via a Github repo. See the \"Github Classroom Setup\" section at the beginning of this document for details on how to do this. You must commit your solution by the due date and time.\n",
    "1. Double check your submission by \"pretending to be the grader\": clone (or download a zip) your submission repo and run your code in a fresh [continuumio/anaconda3:2022.05](https://hub.docker.com/r/continuumio/anaconda3) Docker container like we will when we grade your code."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Grading Guidelines\n",
    "This assignment is worth 100 points. Your assignment will be evaluated based on a successful execution in the [continuumio/anaconda3:2022.05](https://hub.docker.com/r/continuumio/anaconda3) Docker container and adherence to the program requirements. We will grade according to the following criteria:\n",
    "* 10 pts for correct part 1 step 1 (define `test_association_rule_miner_fit()` unit test)\n",
    "* 35 pts for correct part 1 step 2 (finish `fit()` and pass test)\n",
    "* 10 pts for correct part 1 step 3 (finish `print_association_rules()`)\n",
    "* 15 pts for correct part 2 step 1 (titanic rule mining)\n",
    "* 15 pts for correct part 2 step 2 (mushroom rule mining)\n",
    "* 5 pts for no linting problems\n",
    "* 10 pts for adherence to course [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC322/PAs/blob/master/Coding%20Standard.ipynb), including data storytelling (narrative is clear and grammatically correct, Notebook is organized with headers, formulas are typeset with Latex, code receives a \"good\" `pylint` rating, etc.).\n",
    "    * See [coding standard](https://nbviewer.jupyter.org/github/GonzagaCPSC322/PAs/blob/master/Coding%20Standard.ipynb) for details on how to run `pylint` from command line)\n",
    "    * The `pylint` scoring portion of these 10 points is 5 pts scaled to 1/2 of the `pylint` rating, meaning an 8/10 `pylint` rating would score 4/5 pts (rounded to nearest 1/2 integer)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
